{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb4733c7",
   "metadata": {},
   "source": [
    "# Using distilbert model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b1699f",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19941468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54afdbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/raw_train_data.csv', nrows=180000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c9a0d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3600000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    #No whitespaces in beginning or end\n",
    "    text = text.strip()\n",
    "    #lowercase\n",
    "    text= text.lower()\n",
    "    #remove numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "\n",
    "    text = re.sub(rf\"[{re.escape(string.punctuation)}]\", '', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5ecd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b965c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johannesb/.pyenv/versions/3.10.6/envs/sentiscope/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2026, 19204, 17629, 2015, 1998, 2944, 2442, 2674, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-tiny\", padding_side = \"right\")\n",
    "tokenizer(\"My tokenizers and model must match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae730a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2026, 19204, 17629, 2015, 1998, 2944, 2442, 2674, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]\n",
    "\n",
    "first_sentence_tokenized = tokenizer(df[\"text\"][0])\n",
    "\n",
    "first_sentence_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529ba28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModel\n",
    "model = TFAutoModel.from_pretrained(\"prajjwal1/bert-tiny\", from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922ba4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581982</th>\n",
       "      <td>1</td>\n",
       "      <td>those looking for entertainment need not bothe...</td>\n",
       "      <td>those looking for entertainment need not bothe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568876</th>\n",
       "      <td>2</td>\n",
       "      <td>double trouble: this was a funny book. this is...</td>\n",
       "      <td>double trouble this was a funny book this is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3118450</th>\n",
       "      <td>1</td>\n",
       "      <td>Cracktastic Product: I replaced my old filter ...</td>\n",
       "      <td>cracktastic product i replaced my old filter h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131087</th>\n",
       "      <td>1</td>\n",
       "      <td>Not My Cup of Tea: I'd not realized that this ...</td>\n",
       "      <td>not my cup of tea id not realized that this wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820244</th>\n",
       "      <td>1</td>\n",
       "      <td>I was a bit disapointed.: After reading so man...</td>\n",
       "      <td>i was a bit disapointed after reading so many ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text  \\\n",
       "1581982      1  those looking for entertainment need not bothe...   \n",
       "1568876      2  double trouble: this was a funny book. this is...   \n",
       "3118450      1  Cracktastic Product: I replaced my old filter ...   \n",
       "3131087      1  Not My Cup of Tea: I'd not realized that this ...   \n",
       "1820244      1  I was a bit disapointed.: After reading so man...   \n",
       "\n",
       "                                                clean_text  \n",
       "1581982  those looking for entertainment need not bothe...  \n",
       "1568876  double trouble this was a funny book this is a...  \n",
       "3118450  cracktastic product i replaced my old filter h...  \n",
       "3131087  not my cup of tea id not realized that this wa...  \n",
       "1820244  i was a bit disapointed after reading so many ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tensors = tokenizer(df[\"clean_text\"].tolist(), max_length=400, padding = \"max_length\", truncation = True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tensors[\"input_ids\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7bb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 16:18:14.464171: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "tuning_model = TFAutoModelForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\", from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419e1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['label'] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb338380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3600, 400), dtype=int32, numpy=\n",
       "array([[  101,  2216,  2559, ...,     0,     0,     0],\n",
       "       [  101,  3313,  4390, ...,     0,     0,     0],\n",
       "       [  101,  8579, 10230, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  6429, 12124, ...,     0,     0,     0],\n",
       "       [  101,  4299,  2002, ...,     0,     0,     0],\n",
       "       [  101,  9364,  1045, ...,     0,     0,     0]], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = tokenized_tensors[\"input_ids\"]\n",
    "y_train = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae9e877",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_model.compile(optimizer= \"adam\", metrics= \"accuracy\")\n",
    "tuning_model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e67d2",
   "metadata": {},
   "source": [
    "## Saving the model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This way the model can be imported with the .from_pretrained again, this time using the local path\n",
    "tuning_model.save_pretrained(\"../model/bert_tiny_180k\")\n",
    "tokenizer.save_pretrained(\"../model/tokenizer_bert_tiny_180k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505a1cd4",
   "metadata": {},
   "source": [
    "## Load the model with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef08fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 08:54:31.947294: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62ced2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at /Users/johannesb/code/Jojo2813/SentiScope/model/bert_tiny_180k (1).\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "#Load the saved model from your local path\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"/Users/johannesb/code/Jojo2813/SentiScope/model/bert_tiny_180k (1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved tokenizer from local path\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/johannesb/code/Jojo2813/SentiScope/model/tokenizer_bert_tiny_180k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015db7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading 50k test observations\n",
    "X_test = pd.read_csv(\"/Users/johannesb/code/Jojo2813/SentiScope/raw_data/test_df_ml_clean.csv\", nrows= 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec76a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize with tokenizer\n",
    "X_test_tokens = tokenizer(X_test['clean_text'].to_list(), max_length=400, padding = \"max_length\", truncation = True, return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331ea61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 612s 392ms/step\n"
     ]
    }
   ],
   "source": [
    "#Let model predict\n",
    "prediction = model.predict(X_test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the actual label out of the predictions\n",
    "logits = prediction.logits\n",
    "predicted_classes = tf.argmax(logits, axis=1).numpy()\n",
    "\n",
    "y_pred = list(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad8dfdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed48d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89364"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model gets around 90% accuracy on the 50k test rows\n",
    "accuracy_score(X_test['label'], y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
