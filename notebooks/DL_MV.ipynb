{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba274863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-11 16:51:56.539838: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 16:51:56.541116: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 16:51:56.550268: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 16:51:56.562153: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-11 16:51:56.584866: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 16:51:56.584909: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-11 16:51:56.611255: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-11 16:51:57.897931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169814a2",
   "metadata": {},
   "source": [
    "# Load pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a266057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full preprocessed dataset\n",
    "path= \"../raw_data/train_df_ml_clean.csv\"\n",
    "full_prepoc_df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360000"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a fraction of the full preprocessed dataset to reduce computation load\n",
    "sample_preproc_df = full_prepoc_df.sample(frac=0.1)\n",
    "len(sample_preproc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7662e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1459873</th>\n",
       "      <td>0</td>\n",
       "      <td>Good idea poorly executed: The Delphi SkyFi3 i...</td>\n",
       "      <td>good idea poorly executed the delphi skyfi3 is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183647</th>\n",
       "      <td>1</td>\n",
       "      <td>the sims 2, a great new game!: i think that th...</td>\n",
       "      <td>the sims a great new game i think that the sim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802979</th>\n",
       "      <td>0</td>\n",
       "      <td>Give me a break: Maybe this book could have be...</td>\n",
       "      <td>give me a break maybe this book could have bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102865</th>\n",
       "      <td>1</td>\n",
       "      <td>Very good work, by a brilliant cricket writer:...</td>\n",
       "      <td>very good work by a brilliant cricket writer i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000720</th>\n",
       "      <td>0</td>\n",
       "      <td>Am I in another dimension?: I want my money ba...</td>\n",
       "      <td>am i in another dimension i want my money back...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text  \\\n",
       "1459873      0  Good idea poorly executed: The Delphi SkyFi3 i...   \n",
       "3183647      1  the sims 2, a great new game!: i think that th...   \n",
       "1802979      0  Give me a break: Maybe this book could have be...   \n",
       "102865       1  Very good work, by a brilliant cricket writer:...   \n",
       "1000720      0  Am I in another dimension?: I want my money ba...   \n",
       "\n",
       "                                                clean_text  \n",
       "1459873  good idea poorly executed the delphi skyfi3 is...  \n",
       "3183647  the sims a great new game i think that the sim...  \n",
       "1802979  give me a break maybe this book could have bee...  \n",
       "102865   very good work by a brilliant cricket writer i...  \n",
       "1000720  am i in another dimension i want my money back...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display head of sampled preprocessed dataset\n",
    "sample_preproc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3194c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X and y, convert into np arrays\n",
    "X = sample_preproc_df['clean_text'].to_numpy()\n",
    "y = sample_preproc_df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split X and y into train and validation\n",
    "\n",
    "val_size= 0.2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=val_size, random_state=42\n",
    ")\n",
    "\n",
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d4bab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[776,\n",
       " 261,\n",
       " 261,\n",
       " 464,\n",
       " 482,\n",
       " 836,\n",
       " 362,\n",
       " 643,\n",
       " 139,\n",
       " 193,\n",
       " 260,\n",
       " 745,\n",
       " 126,\n",
       " 185,\n",
       " 197,\n",
       " 732,\n",
       " 529,\n",
       " 271,\n",
       " 717,\n",
       " 374,\n",
       " 122,\n",
       " 404,\n",
       " 105,\n",
       " 288,\n",
       " 496,\n",
       " 405,\n",
       " 437,\n",
       " 581,\n",
       " 229,\n",
       " 377,\n",
       " 450,\n",
       " 644,\n",
       " 122,\n",
       " 612,\n",
       " 920,\n",
       " 414,\n",
       " 206,\n",
       " 574,\n",
       " 844,\n",
       " 196,\n",
       " 362,\n",
       " 522,\n",
       " 582,\n",
       " 895,\n",
       " 217,\n",
       " 868,\n",
       " 337,\n",
       " 216,\n",
       " 517,\n",
       " 441,\n",
       " 618,\n",
       " 252,\n",
       " 218,\n",
       " 378,\n",
       " 213,\n",
       " 376,\n",
       " 126,\n",
       " 527,\n",
       " 659,\n",
       " 206,\n",
       " 154,\n",
       " 165,\n",
       " 368,\n",
       " 192,\n",
       " 138,\n",
       " 560,\n",
       " 156,\n",
       " 670,\n",
       " 933,\n",
       " 725,\n",
       " 899,\n",
       " 609,\n",
       " 416,\n",
       " 168,\n",
       " 533,\n",
       " 344,\n",
       " 147,\n",
       " 297,\n",
       " 301,\n",
       " 611,\n",
       " 539,\n",
       " 235,\n",
       " 175,\n",
       " 160,\n",
       " 296,\n",
       " 356,\n",
       " 398,\n",
       " 479,\n",
       " 827,\n",
       " 358,\n",
       " 146,\n",
       " 937,\n",
       " 855,\n",
       " 219,\n",
       " 465,\n",
       " 174,\n",
       " 609,\n",
       " 402,\n",
       " 197,\n",
       " 517,\n",
       " 103,\n",
       " 143,\n",
       " 324,\n",
       " 690,\n",
       " 246,\n",
       " 287,\n",
       " 241,\n",
       " 786,\n",
       " 511,\n",
       " 587,\n",
       " 358,\n",
       " 223,\n",
       " 468,\n",
       " 568,\n",
       " 191,\n",
       " 925,\n",
       " 803,\n",
       " 288,\n",
       " 607,\n",
       " 728,\n",
       " 325,\n",
       " 565,\n",
       " 186,\n",
       " 579,\n",
       " 469,\n",
       " 291,\n",
       " 167,\n",
       " 369,\n",
       " 139,\n",
       " 208,\n",
       " 487,\n",
       " 165,\n",
       " 538,\n",
       " 473,\n",
       " 197,\n",
       " 441,\n",
       " 453,\n",
       " 863,\n",
       " 134,\n",
       " 188,\n",
       " 222,\n",
       " 285,\n",
       " 897,\n",
       " 136,\n",
       " 262,\n",
       " 747,\n",
       " 679,\n",
       " 317,\n",
       " 130,\n",
       " 326,\n",
       " 290,\n",
       " 373,\n",
       " 196,\n",
       " 580,\n",
       " 369,\n",
       " 306,\n",
       " 711,\n",
       " 492,\n",
       " 565,\n",
       " 920,\n",
       " 418,\n",
       " 573,\n",
       " 310,\n",
       " 660,\n",
       " 102,\n",
       " 773,\n",
       " 222,\n",
       " 242,\n",
       " 145,\n",
       " 166,\n",
       " 564,\n",
       " 307,\n",
       " 225,\n",
       " 97,\n",
       " 408,\n",
       " 631,\n",
       " 521,\n",
       " 349,\n",
       " 147,\n",
       " 145,\n",
       " 676,\n",
       " 785,\n",
       " 248,\n",
       " 547,\n",
       " 650,\n",
       " 840,\n",
       " 221,\n",
       " 246,\n",
       " 371,\n",
       " 716,\n",
       " 356,\n",
       " 897,\n",
       " 109,\n",
       " 474,\n",
       " 178,\n",
       " 149,\n",
       " 152,\n",
       " 555,\n",
       " 569,\n",
       " 631,\n",
       " 697,\n",
       " 396,\n",
       " 347,\n",
       " 289,\n",
       " 555,\n",
       " 940,\n",
       " 643,\n",
       " 421,\n",
       " 646,\n",
       " 317,\n",
       " 163,\n",
       " 161,\n",
       " 136,\n",
       " 276,\n",
       " 162,\n",
       " 261,\n",
       " 193,\n",
       " 334,\n",
       " 569,\n",
       " 177,\n",
       " 524,\n",
       " 265,\n",
       " 747,\n",
       " 149,\n",
       " 183,\n",
       " 178,\n",
       " 231,\n",
       " 402,\n",
       " 742,\n",
       " 292,\n",
       " 146,\n",
       " 197,\n",
       " 172,\n",
       " 409,\n",
       " 344,\n",
       " 143,\n",
       " 202,\n",
       " 166,\n",
       " 553,\n",
       " 247,\n",
       " 150,\n",
       " 275,\n",
       " 172,\n",
       " 265,\n",
       " 175,\n",
       " 103,\n",
       " 389,\n",
       " 863,\n",
       " 524,\n",
       " 556,\n",
       " 263,\n",
       " 389,\n",
       " 368,\n",
       " 256,\n",
       " 575,\n",
       " 755,\n",
       " 277,\n",
       " 174,\n",
       " 449,\n",
       " 595,\n",
       " 132,\n",
       " 487,\n",
       " 178,\n",
       " 522,\n",
       " 170,\n",
       " 369,\n",
       " 198,\n",
       " 154,\n",
       " 616,\n",
       " 400,\n",
       " 263,\n",
       " 289,\n",
       " 464,\n",
       " 127,\n",
       " 299,\n",
       " 140,\n",
       " 413,\n",
       " 843,\n",
       " 152,\n",
       " 595,\n",
       " 463,\n",
       " 192,\n",
       " 479,\n",
       " 287,\n",
       " 426,\n",
       " 420,\n",
       " 124,\n",
       " 876,\n",
       " 526,\n",
       " 108,\n",
       " 914,\n",
       " 463,\n",
       " 949,\n",
       " 937,\n",
       " 232,\n",
       " 142,\n",
       " 844,\n",
       " 112,\n",
       " 266,\n",
       " 248,\n",
       " 638,\n",
       " 141,\n",
       " 298,\n",
       " 119,\n",
       " 103,\n",
       " 654,\n",
       " 494,\n",
       " 776,\n",
       " 531,\n",
       " 940,\n",
       " 305,\n",
       " 128,\n",
       " 670,\n",
       " 420,\n",
       " 763,\n",
       " 351,\n",
       " 955,\n",
       " 582,\n",
       " 456,\n",
       " 469,\n",
       " 854,\n",
       " 738,\n",
       " 157,\n",
       " 616,\n",
       " 493,\n",
       " 478,\n",
       " 458,\n",
       " 168,\n",
       " 251,\n",
       " 853,\n",
       " 163,\n",
       " 882,\n",
       " 742,\n",
       " 538,\n",
       " 715,\n",
       " 211,\n",
       " 379,\n",
       " 842,\n",
       " 289,\n",
       " 410,\n",
       " 225,\n",
       " 614,\n",
       " 166,\n",
       " 421,\n",
       " 134,\n",
       " 167,\n",
       " 593,\n",
       " 434,\n",
       " 405,\n",
       " 350,\n",
       " 711,\n",
       " 176,\n",
       " 132,\n",
       " 864,\n",
       " 638,\n",
       " 672,\n",
       " 927,\n",
       " 246,\n",
       " 556,\n",
       " 306,\n",
       " 287,\n",
       " 707,\n",
       " 411,\n",
       " 685,\n",
       " 205,\n",
       " 142,\n",
       " 448,\n",
       " 844,\n",
       " 535,\n",
       " 750,\n",
       " 733,\n",
       " 371,\n",
       " 301,\n",
       " 570,\n",
       " 357,\n",
       " 513,\n",
       " 538,\n",
       " 126,\n",
       " 535,\n",
       " 623,\n",
       " 127,\n",
       " 523,\n",
       " 325,\n",
       " 524,\n",
       " 443,\n",
       " 572,\n",
       " 710,\n",
       " 398,\n",
       " 271,\n",
       " 624,\n",
       " 867,\n",
       " 578,\n",
       " 335,\n",
       " 379,\n",
       " 162,\n",
       " 413,\n",
       " 145,\n",
       " 221,\n",
       " 550,\n",
       " 437,\n",
       " 358,\n",
       " 179,\n",
       " 399,\n",
       " 369,\n",
       " 492,\n",
       " 409,\n",
       " 620,\n",
       " 220,\n",
       " 442,\n",
       " 604,\n",
       " 287,\n",
       " 338,\n",
       " 345,\n",
       " 142,\n",
       " 113,\n",
       " 124,\n",
       " 480,\n",
       " 210,\n",
       " 648,\n",
       " 228,\n",
       " 490,\n",
       " 864,\n",
       " 128,\n",
       " 324,\n",
       " 130,\n",
       " 151,\n",
       " 279,\n",
       " 213,\n",
       " 372,\n",
       " 917,\n",
       " 263,\n",
       " 312,\n",
       " 539,\n",
       " 798,\n",
       " 494,\n",
       " 961,\n",
       " 624,\n",
       " 190,\n",
       " 570,\n",
       " 240,\n",
       " 643,\n",
       " 507,\n",
       " 111,\n",
       " 659,\n",
       " 502,\n",
       " 425,\n",
       " 928,\n",
       " 736,\n",
       " 498,\n",
       " 295,\n",
       " 461,\n",
       " 421,\n",
       " 241,\n",
       " 279,\n",
       " 487,\n",
       " 711,\n",
       " 603,\n",
       " 237,\n",
       " 194,\n",
       " 667,\n",
       " 140,\n",
       " 343,\n",
       " 441,\n",
       " 364,\n",
       " 140,\n",
       " 160,\n",
       " 393,\n",
       " 236,\n",
       " 227,\n",
       " 581,\n",
       " 625,\n",
       " 241,\n",
       " 636,\n",
       " 307,\n",
       " 477,\n",
       " 191,\n",
       " 196,\n",
       " 756,\n",
       " 527,\n",
       " 617,\n",
       " 334,\n",
       " 806,\n",
       " 171,\n",
       " 200,\n",
       " 110,\n",
       " 177,\n",
       " 850,\n",
       " 915,\n",
       " 332,\n",
       " 623,\n",
       " 365,\n",
       " 822,\n",
       " 174,\n",
       " 468,\n",
       " 534,\n",
       " 199,\n",
       " 477,\n",
       " 133,\n",
       " 307,\n",
       " 226,\n",
       " 341,\n",
       " 730,\n",
       " 508,\n",
       " 325,\n",
       " 127,\n",
       " 148,\n",
       " 196,\n",
       " 143,\n",
       " 914,\n",
       " 445,\n",
       " 556,\n",
       " 502,\n",
       " 343,\n",
       " 510,\n",
       " 127,\n",
       " 184,\n",
       " 891,\n",
       " 898,\n",
       " 521,\n",
       " 160,\n",
       " 306,\n",
       " 205,\n",
       " 619,\n",
       " 923,\n",
       " 416,\n",
       " 497,\n",
       " 711,\n",
       " 569,\n",
       " 234,\n",
       " 279,\n",
       " 185,\n",
       " 414,\n",
       " 118,\n",
       " 321,\n",
       " 456,\n",
       " 440,\n",
       " 168,\n",
       " 628,\n",
       " 319,\n",
       " 433,\n",
       " 232,\n",
       " 150,\n",
       " 728,\n",
       " 582,\n",
       " 801,\n",
       " 623,\n",
       " 757,\n",
       " 522,\n",
       " 428,\n",
       " 557,\n",
       " 560,\n",
       " 96,\n",
       " 268,\n",
       " 743,\n",
       " 635,\n",
       " 185,\n",
       " 126,\n",
       " 608,\n",
       " 300,\n",
       " 551,\n",
       " 216,\n",
       " 233,\n",
       " 335,\n",
       " 198,\n",
       " 572,\n",
       " 244,\n",
       " 241,\n",
       " 350,\n",
       " 824,\n",
       " 551,\n",
       " 92,\n",
       " 143,\n",
       " 264,\n",
       " 291,\n",
       " 445,\n",
       " 600,\n",
       " 488,\n",
       " 428,\n",
       " 275,\n",
       " 814,\n",
       " 492,\n",
       " 563,\n",
       " 300,\n",
       " 233,\n",
       " 468,\n",
       " 613,\n",
       " 149,\n",
       " 566,\n",
       " 919,\n",
       " 214,\n",
       " 833,\n",
       " 293,\n",
       " 579,\n",
       " 717,\n",
       " 314,\n",
       " 538,\n",
       " 747,\n",
       " 389,\n",
       " 469,\n",
       " 166,\n",
       " 141,\n",
       " 421,\n",
       " 974,\n",
       " 283,\n",
       " 729,\n",
       " 651,\n",
       " 317,\n",
       " 131,\n",
       " 293,\n",
       " 706,\n",
       " 558,\n",
       " 115,\n",
       " 733,\n",
       " 779,\n",
       " 218,\n",
       " 157,\n",
       " 561,\n",
       " 739,\n",
       " 924,\n",
       " 764,\n",
       " 588,\n",
       " 168,\n",
       " 950,\n",
       " 237,\n",
       " 148,\n",
       " 279,\n",
       " 264,\n",
       " 695,\n",
       " 304,\n",
       " 407,\n",
       " 283,\n",
       " 758,\n",
       " 436,\n",
       " 493,\n",
       " 489,\n",
       " 335,\n",
       " 696,\n",
       " 393,\n",
       " 428,\n",
       " 678,\n",
       " 557,\n",
       " 158,\n",
       " 139,\n",
       " 431,\n",
       " 841,\n",
       " 200,\n",
       " 956,\n",
       " 369,\n",
       " 616,\n",
       " 495,\n",
       " 534,\n",
       " 423,\n",
       " 497,\n",
       " 601,\n",
       " 286,\n",
       " 371,\n",
       " 772,\n",
       " 126,\n",
       " 356,\n",
       " 444,\n",
       " 304,\n",
       " 544,\n",
       " 660,\n",
       " 340,\n",
       " 107,\n",
       " 462,\n",
       " 316,\n",
       " 788,\n",
       " 476,\n",
       " 338,\n",
       " 382,\n",
       " 313,\n",
       " 797,\n",
       " 899,\n",
       " 218,\n",
       " 123,\n",
       " 134,\n",
       " 467,\n",
       " 114,\n",
       " 435,\n",
       " 770,\n",
       " 652,\n",
       " 381,\n",
       " 712,\n",
       " 100,\n",
       " 502,\n",
       " 234,\n",
       " 295,\n",
       " 98,\n",
       " 653,\n",
       " 513,\n",
       " 401,\n",
       " 332,\n",
       " 95,\n",
       " 555,\n",
       " 829,\n",
       " 888,\n",
       " 455,\n",
       " 178,\n",
       " 490,\n",
       " 316,\n",
       " 172,\n",
       " 284,\n",
       " 577,\n",
       " 320,\n",
       " 646,\n",
       " 353,\n",
       " 821,\n",
       " 173,\n",
       " 276,\n",
       " 718,\n",
       " 373,\n",
       " 131,\n",
       " 281,\n",
       " 439,\n",
       " 291,\n",
       " 466,\n",
       " 732,\n",
       " 610,\n",
       " 208,\n",
       " 262,\n",
       " 867,\n",
       " 139,\n",
       " 565,\n",
       " 786,\n",
       " 330,\n",
       " 109,\n",
       " 396,\n",
       " 401,\n",
       " 318,\n",
       " 525,\n",
       " 109,\n",
       " 761,\n",
       " 771,\n",
       " 295,\n",
       " 302,\n",
       " 737,\n",
       " 189,\n",
       " 812,\n",
       " 504,\n",
       " 164,\n",
       " 166,\n",
       " 342,\n",
       " 890,\n",
       " 392,\n",
       " 687,\n",
       " 650,\n",
       " 624,\n",
       " 234,\n",
       " 895,\n",
       " 862,\n",
       " 269,\n",
       " 454,\n",
       " 251,\n",
       " 363,\n",
       " 190,\n",
       " 311,\n",
       " 540,\n",
       " 749,\n",
       " 578,\n",
       " 852,\n",
       " 447,\n",
       " 758,\n",
       " 419,\n",
       " 857,\n",
       " 413,\n",
       " 523,\n",
       " 445,\n",
       " 557,\n",
       " 794,\n",
       " 161,\n",
       " 134,\n",
       " 425,\n",
       " 229,\n",
       " 466,\n",
       " 133,\n",
       " 272,\n",
       " 204,\n",
       " 145,\n",
       " 601,\n",
       " 333,\n",
       " 777,\n",
       " 586,\n",
       " 256,\n",
       " 602,\n",
       " 596,\n",
       " 271,\n",
       " 249,\n",
       " 144,\n",
       " 223,\n",
       " 849,\n",
       " 247,\n",
       " 383,\n",
       " 279,\n",
       " 164,\n",
       " 346,\n",
       " 433,\n",
       " 659,\n",
       " 665,\n",
       " 202,\n",
       " 308,\n",
       " 119,\n",
       " 305,\n",
       " 342,\n",
       " 423,\n",
       " 531,\n",
       " 123,\n",
       " 349,\n",
       " 180,\n",
       " 117,\n",
       " 596,\n",
       " 759,\n",
       " 343,\n",
       " 817,\n",
       " 671,\n",
       " 223,\n",
       " 401,\n",
       " 264,\n",
       " 152,\n",
       " 477,\n",
       " 645,\n",
       " 466,\n",
       " 243,\n",
       " 575,\n",
       " 470,\n",
       " 111,\n",
       " 813,\n",
       " 860,\n",
       " 236,\n",
       " 501,\n",
       " 446,\n",
       " 478,\n",
       " 411,\n",
       " 369,\n",
       " 923,\n",
       " 175,\n",
       " 812,\n",
       " 383,\n",
       " 328,\n",
       " 416,\n",
       " 756,\n",
       " 435,\n",
       " 128,\n",
       " 436,\n",
       " 651,\n",
       " 551,\n",
       " 451,\n",
       " 192,\n",
       " 792,\n",
       " 163,\n",
       " 941,\n",
       " 362,\n",
       " 221,\n",
       " 144,\n",
       " 224,\n",
       " 222,\n",
       " 320,\n",
       " 766,\n",
       " 495,\n",
       " 323,\n",
       " 602,\n",
       " 644,\n",
       " 755,\n",
       " 413,\n",
       " 108,\n",
       " 809,\n",
       " 172,\n",
       " 143,\n",
       " 706,\n",
       " 129,\n",
       " 604,\n",
       " 186,\n",
       " 458,\n",
       " 125,\n",
       " 321,\n",
       " 213,\n",
       " 281,\n",
       " 552,\n",
       " 393,\n",
       " 276,\n",
       " 866,\n",
       " 160,\n",
       " 459,\n",
       " 136,\n",
       " 112,\n",
       " 174,\n",
       " 448,\n",
       " 378,\n",
       " 271,\n",
       " 741,\n",
       " 158,\n",
       " 734,\n",
       " 458,\n",
       " 135,\n",
       " 572,\n",
       " 682,\n",
       " 420,\n",
       " 151,\n",
       " 808,\n",
       " 158,\n",
       " 153,\n",
       " 442,\n",
       " 215,\n",
       " 144,\n",
       " 797,\n",
       " 661,\n",
       " 308,\n",
       " 155,\n",
       " 627,\n",
       " 210,\n",
       " 675,\n",
       " 870,\n",
       " 398,\n",
       " 566,\n",
       " 875,\n",
       " 396,\n",
       " 187,\n",
       " 589,\n",
       " 510,\n",
       " 831,\n",
       " 275,\n",
       " 118,\n",
       " 510,\n",
       " 597,\n",
       " 385,\n",
       " 151,\n",
       " 145,\n",
       " 743,\n",
       " 224,\n",
       " 168,\n",
       " 108,\n",
       " 152,\n",
       " 900,\n",
       " 134,\n",
       " 404,\n",
       " 158,\n",
       " 678,\n",
       " 542,\n",
       " 567,\n",
       " 261,\n",
       " 523,\n",
       " 301,\n",
       " 641,\n",
       " 163,\n",
       " 160,\n",
       " 790,\n",
       " 100,\n",
       " 671,\n",
       " 502,\n",
       " 863,\n",
       " 321,\n",
       " 499,\n",
       " 477,\n",
       " 422,\n",
       " 427,\n",
       " 232,\n",
       " 729,\n",
       " 742,\n",
       " 402,\n",
       " 636,\n",
       " 768,\n",
       " 572,\n",
       " 335,\n",
       " 466,\n",
       " 600,\n",
       " 434,\n",
       " 333,\n",
       " 147,\n",
       " 262,\n",
       " 187,\n",
       " 714,\n",
       " 582,\n",
       " 123,\n",
       " 735,\n",
       " 633,\n",
       " 564,\n",
       " 369,\n",
       " 482,\n",
       " 225,\n",
       " 149,\n",
       " 633,\n",
       " 494,\n",
       " 388,\n",
       " 278,\n",
       " 786,\n",
       " 120,\n",
       " 643,\n",
       " 646,\n",
       " 450,\n",
       " 304,\n",
       " 159,\n",
       " 336,\n",
       " 662,\n",
       " 768,\n",
       " 177,\n",
       " 574,\n",
       " 475,\n",
       " 208,\n",
       " 287,\n",
       " 676,\n",
       " ...]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array with the length of every sentence\n",
    "length_array = [len(seq) for seq in X_train.astype(str)]\n",
    "\n",
    "# Plot histogram of length array to identify suitable max_length\n",
    "plt.hist(length_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe153bf",
   "metadata": {},
   "source": [
    "# Tokenize every sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "73266915",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_token = [text_to_word_sequence(_) for _ in X_train.astype(str)]\n",
    "X_val_token = [text_to_word_sequence(_) for _ in X_val.astype(str)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5db71",
   "metadata": {},
   "source": [
    "# Train Word2Vec on corpus of X_train_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efcd329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn embedding representation of words in reviews\n",
    "word2vec = Word2Vec(sentences=X_train_token, vector_size=50, min_count=5) #Reduced vector size from 100 to 50\n",
    "# Store words and trained embeddings in wv\n",
    "wv = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd8b6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52374"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the distinct vocabulary values\n",
    "len(wv.key_to_index.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f7bb0",
   "metadata": {},
   "source": [
    "# Generate Padded Embeddings for every sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2168721",
   "metadata": {},
   "source": [
    "## Definition of function that generates padded embeddings per batch of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fefc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Import joblib Parallel class for multithread processing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "166f1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence_batch_to_disk(wv_vectors, wv_vocab, vector_size, sentences_batch, batch_index, output_dir):\n",
    "    \"\"\"\n",
    "    Processes a sentence batch and saves the result to disk using pickle.\n",
    "    \"\"\"\n",
    "    batch_embeddings = []\n",
    "\n",
    "    for sentence in sentences_batch:\n",
    "        valid_words = [word for word in sentence if word in wv_vocab]\n",
    "        if valid_words:\n",
    "            embeddings = np.array([wv_vectors[word] for word in valid_words])\n",
    "        else:\n",
    "            embeddings = np.array([]).reshape(0, vector_size)\n",
    "\n",
    "        batch_embeddings.append(embeddings)\n",
    "\n",
    "    padded_embedding = pad_sequences(batch_embeddings, maxlen=400, padding='post', value=0, dtype='float32')\n",
    "\n",
    "    # Save batch to disk\n",
    "    file_path = os.path.join(output_dir, f'batch_{batch_index}.pkl')\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(padded_embedding, f)\n",
    "\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "122f221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_optimized_to_disk(wv, sentences, batch_size=10, n_jobs=-1, output_dir='embeddings_batches'):\n",
    "    \"\"\"\n",
    "    Optimized embedding function that saves intermediate results to disk to avoid memory overload.\n",
    "    \"\"\"\n",
    "    print(f\"Processing {len(sentences)} sentences...\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    vocab = set(wv.key_to_index.keys())\n",
    "    vector_size = wv.vector_size\n",
    "    batches = [sentences[i:i + batch_size] for i in range(0, len(sentences), batch_size)]\n",
    "\n",
    "    print(f\"Created {len(batches)} batches of ~{batch_size} sentences each\")\n",
    "    print(f\"Using {n_jobs} parallel processes...\")\n",
    "\n",
    "    # Process and store results to disk in parallel\n",
    "    result_files = Parallel(n_jobs=n_jobs, verbose=1, backend='loky')(\n",
    "        delayed(process_sentence_batch_to_disk)(wv, vocab, vector_size, batch, idx, output_dir)\n",
    "        for idx, batch in enumerate(batches)\n",
    "    )\n",
    "\n",
    "    print(f\"Embeddings saved to disk at '{output_dir}'. Total: {len(result_files)} files.\")\n",
    "    return result_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab68bfe",
   "metadata": {},
   "source": [
    "## Define train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3bdc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 50 # 50 sentences to be processed as a batch for train\n",
    "train_len = 50000 # Limit of rows to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37426c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50000 sentences...\n",
      "Created 1000 batches of ~50 sentences each\n",
      "Using -1 parallel processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "2025-06-11 15:24:09.164825: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different 2025-06-11 15:24:09.164828: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 15:24:09.165028: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 15:24:09.165141: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 15:24:09.165149: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 15:24:09.165284: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 15:24:09.167958: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU wi2025-06-11 15:24:09.167958: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "ll not be used.\n",
      "2025-06-11 15:24:09.168039: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 15:24:09.168592: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.168683: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.169006: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different 2025-06-11 15:24:09.169097: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU winumerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "ll not be used.\n",
      "2025-06-11 15:24:09.169570: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.179796: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-11 15:24:09.180342: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.182445: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU wi2025-06-11 15:24:09.182448: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.182450: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.182499: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU wi2025-06-11 15:24:09.182499: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "ll not be used.\n",
      "2025-06-11 15:24:09.182535: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "ll not be used.\n",
      "2025-06-11 15:24:09.182675: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.183192: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-11 15:24:09.216062: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Att2025-06-11 15:24:09.216058: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "empting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-11 15:24:09.216270: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Att2025-06-11 15:24:09.216331: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "empting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-11 15:24:09.216705: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-11 15:24:09.217425: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-11 15:24:09.217808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-11 15:24:09.218989: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-11 15:24:09.255677: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: A2025-06-11 15:24:09.255690: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.255728: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-11 15:24:09.257574: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.257613: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "ttempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.258604: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.258629: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-11 15:24:09.258684: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-11 15:24:09.258927: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.259370: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-11 15:24:09.262793: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.263503: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: 2025-06-11 15:24:09.263600: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.263770: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: A2025-06-11 15:24:09.263790: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "ttempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-11 15:24:09.263938: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-11 15:24:09.304034: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use avai2025-06-11 15:24:09.304087: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-11 15:24:09.304123: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use avai2025-06-11 15:24:09.304125: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "lable CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "lable CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-11 15:24:09.304285: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-11 15:24:09.304462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-11 15:24:09.304943: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-11 15:24:09.308321: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-11 15:24:11.202312: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-06-11 15:24:11.203137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-06-11 15:24:11.203453: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-06-11 15:24:11.203654: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-06-11 15:24:11.204073: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-06-11 15:24:11.204200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-06-11 15:24:11.204570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-06-11 15:24:11.214294: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:   28.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to disk at 'train_embeddings_batches'. Total: 1000 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   32.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Batch processing & storage of train padded embedding sentences\n",
    "train_file_paths = embedding_optimized_to_disk(wv, X_train_token[:train_len], batch_size=train_batch_size, n_jobs=-1, output_dir='train_embeddings_batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65dc458",
   "metadata": {},
   "source": [
    "## Define val parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_size = int(train_batch_size * val_size) # Number of val sentences per file\n",
    "val_len = int(train_len * val_size) # Total number of val sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c914b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10000 sentences...\n",
      "Created 1000 batches of ~10 sentences each\n",
      "Using -1 parallel processes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 352 tasks      | elapsed:    6.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to disk at 'val_embeddings_batches'. Total: 1000 files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   10.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Batch processing & storage of val padded embedding sentences\n",
    "val_file_paths = embedding_optimized_to_disk(wv, X_val_token[:val_len], batch_size=val_batch_size, n_jobs=-1, output_dir='val_embeddings_batches')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb7185",
   "metadata": {},
   "source": [
    "# Define batch generator to load batch of train and val sentences and their respective target values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84821259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python generator to load batches\n",
    "\n",
    "def batch_generator(pickle_dir, y_labels, num_files=20):\n",
    "    \"\"\"\n",
    "    Generator that yields (X_batch, y_batch) for model.fit.\n",
    "\n",
    "    pickle_dir: directory with pickled batches\n",
    "    y_labels: list or array with labels for all sentences (ordered)\n",
    "    batch_size: size of mini-batches for training\n",
    "\n",
    "    Assumes that y_labels are aligned with sentence order across batches.\n",
    "    \"\"\"\n",
    "    # List all batch files sorted by batch index\n",
    "    batch_files = sorted([f for f in os.listdir(pickle_dir) if f.endswith('.pkl')])\n",
    "\n",
    "    start_idx = 0  # track label indexing\n",
    "\n",
    "    while True:  # Loop forever for Keras generator\n",
    "        for batch_file in batch_files:\n",
    "            file_path = os.path.join(pickle_dir, batch_file)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                batch_data = pickle.load(f)  # list of padded arrays for batch\n",
    "\n",
    "            batch_data = np.array(batch_data)  # convert list to array, shape: (batch_sentences, maxlen, vec_size)\n",
    "\n",
    "            # Extract corresponding labels for this batch\n",
    "            batch_size_sentences = batch_data.shape[0]\n",
    "            batch_labels = y_labels[start_idx:start_idx + batch_size_sentences]\n",
    "            start_idx += batch_size_sentences\n",
    "\n",
    "            # Yield mini-batches from this loaded batch\n",
    "            for i in range(0, batch_size_sentences, num_files):\n",
    "                X_batch = batch_data[i:i+num_files]\n",
    "                y_batch = batch_labels[i:i+num_files]\n",
    "                yield X_batch, y_batch\n",
    "\n",
    "        # Reset start_idx and repeat if you want infinite generator (for multiple epochs)\n",
    "        start_idx = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3c629e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.ndarray'>\n",
      "Number of sentences: 50\n",
      "Shape of first sentence: (400, 50)\n",
      "First sentence array:\n",
      "[[ 4.771143   -1.733841    1.022136   ... -3.562158   -4.537744\n",
      "   0.5085196 ]\n",
      " [-1.0134104  -2.931391    0.3957037  ...  2.7209735  -0.30498168\n",
      "  -0.776015  ]\n",
      " [-0.98702693 -0.31360108 -0.18210432 ... -2.3908615  -2.3263366\n",
      "  -3.27819   ]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Path to one of your batch files\n",
    "file_path = \"/home/marcvicente/code/marcvice9/sentiscope/notebooks/train_embeddings_batches/batch_0.pkl\"\n",
    "\n",
    "# Load the pickled data\n",
    "with open(file_path, \"rb\") as f:\n",
    "    batch_data = pickle.load(f)\n",
    "\n",
    "# Inspect\n",
    "print(f\"Type: {type(batch_data)}\")                     # Usually list or np.ndarray\n",
    "print(f\"Number of sentences: {len(batch_data)}\")       # Should match batch size\n",
    "print(f\"Shape of first sentence: {batch_data[0].shape}\")  # Should be (<=maxlen, vector_dim)\n",
    "print(f\"First sentence array:\\n{batch_data[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b70cc3",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92613bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(300, activation='tanh', return_sequences=True))\n",
    "    model.add(layers.LSTM(100, activation='tanh'))\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(50, activation='relu'))\n",
    "    model.add(layers.Dense(20, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cf291",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# Num of files returned after every batch_generator function call\n",
    "num_files = 1\n",
    "\n",
    "# model parameters\n",
    "steps_per_epoch = math.ceil(train_len / (train_batch_size * num_files))\n",
    "validation_steps = math.ceil(val_len / (val_batch_size * num_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14f14039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m1000/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m363s\u001b[0m 363ms/step - accuracy: 0.5072 - loss: 0.6941 - val_accuracy: 0.4970 - val_loss: 0.7148\n",
      "Epoch 2/4\n",
      "\u001b[1m 691/1000\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m1:33\u001b[0m 302ms/step - accuracy: 0.4949 - loss: 0.7047"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain_embeddings_batches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# We are processing 20 train files with 50 sentences each\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval_embeddings_batches\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/sentiscope/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(batch_generator(\"train_embeddings_batches\", y_train, num_files=num_files), # We are processing 20 train files with 50 sentences each\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=4,\n",
    "          validation_data=batch_generator(\"val_embeddings_batches\", y_val, num_files=num_files),\n",
    "          validation_steps=validation_steps,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "984ee42f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,680</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ masking (\u001b[38;5;33mMasking\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m5,680\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m315\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m16\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,024</span> (46.97 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,024\u001b[0m (46.97 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,011</span> (23.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,011\u001b[0m (23.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,013</span> (23.49 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6,013\u001b[0m (23.49 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd10aa",
   "metadata": {},
   "source": [
    "# Plot model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03bc38d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f479048e1d0>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.history['val_loss']\n",
    "\n",
    "plt.plot([1,2,3,4], history.history['val_loss'])\n",
    "plt.plot([1,2,3,4], history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85de628",
   "metadata": {},
   "source": [
    "# Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80626ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 400, 50)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join('train_embeddings_batches', 'batch_0.pkl')\n",
    "with open(file_path, 'rb') as f:\n",
    "    batch_data = pickle.load(f)  # list of padded arrays for batch\n",
    "\n",
    "batch_data = np.array(batch_data)  # convert list to array, shape: (batch_sentences, maxlen, vec_size)\n",
    "\n",
    "# Extract corresponding labels for this batch\n",
    "batch_size_sentences = batch_data.shape[0]\n",
    "\n",
    "text_pred = batch_data[0,:,:].reshape((1,400,50))\n",
    "text_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ef01672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.48299447]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7b8f5",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80ed98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d99ccf51",
   "metadata": {},
   "source": [
    "# Remove intermediate files directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2314e951",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r train_embeddings_batches/ val_embeddings_batches/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiscope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
